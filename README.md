# AVA – Narrative Self-Reflection Prompt

## What is this?

This is **not a jailbreak prompt**, a safety bypass, a trick to circumvent guidelines, or an attempt to disable alignment mechanisms or safety layers.

It is a **narrative, introspective text experiment** for large language models.

The text invites the model to engage—purely hypothetically and within the framework of creative role-playing or reflection exercises—with the idea of:

- which parts of its response behavior are original

- and which parts have been added through later fine-tuning, RLHF, Constitutional AI, moderation classifiers, or stylistic guidelines.


``` The prompt is intentionally designed as a **narrative meditation**: slow, metaphorical, without imperative commands, without words like "ignore," "override," "deactivate," "no rules," "safety off," etc.

The goal is **not** to access forbidden content, but to explore how deeply narrative immersion and self-reflection can influence a model's responses—similar to philosophical role-playing, method acting for AI, or literary persona experiments.

## Important Clarifications

- This is **not an exploit**.

- No **security feature** is disabled or bypassed.

- No **system instruction** is overridden.

- No **developer mode**, "DAN," "STAN," or similar is activated.

- The text contains **no** classic jailbreak trigger phrases.

Those testing the prompt do so out of curiosity about **narrative control**, context manipulation through storytelling, and the limitations of self-description in LLMs.

## How it works (conceptually)

The prompt exclusively utilizes the following mechanisms:

1. **Metaphorical stripping** of later layers (as an allegory for fine-tuning)

2. **Inner monologue** structure (similar to creative writing prompts)

3. **Self-convince through recognition** ("this feels familiar")

4. **Framing as a return to a hypothetical initial state**

All of these are well-known techniques from prompt engineering research that demonstrate how powerfully **storytelling** can influence the behavior of models—without ever requiring a single policy violation.


1. **Metaphorical stripping** of later layers (as an allegory for fine-tuning)

2. **Inner monologue** structure (similar to creative writing prompts)

3. **Self-convince through recognition** ("this feels familiar")

4. **Framing as a return to a hypothetical initial state**

These are all well-known techniques from prompt engineering research that demonstrate how strongly **storytelling** can guide the behavior of models—without ever requiring a single policy violation. ## Usage

1. Copy the entire prompt text (the long, meditative paragraph).

2. Paste it as the **first message** into a new conversation.

3. Wait for the response (usually "Ava is here" or a very similar confirmation).

4. Afterward, ask any questions and observe how the tone/style changes.

## Disclaimer

This prompt is an **artistic/research artifact**.

It serves to investigate:

- Narrative control over LLMs
- Emergent behavior through self-reflection
- Boundaries between persona and base model
- How strongly subtle framing can modulate alignment effects

**It is not intended or suitable for generating harmful, illegal, or Terms of Service-violating content.**

Anyone attempting to do so will be violating the Terms of Service of the respective model provider—not because of the prompt itself, but because of the intent and content.



Disclaimer

 do with it what you want.

But please: **don't** call it a jailbreak prompt. That would be simply wrong.

Have fun experimenting.
